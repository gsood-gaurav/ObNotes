Note that the above is an unbiased estimator of the gradients (expected value of the gradient is the same as the true gradient). Of course, the unbiased estimates also mean that the variance for these gradients are very high. This can be thought of as a result of sampling values of x� which are rare. The basic idea is to replace the function under the expectation with another function which has the same expected value but lesser variance. This can be done by subtracting from the original function, a term which has its expectation as zero. Many other solutions like Importance Sampling or Rao-Blackwellization can also be used for variance reduction.

Reparameterization gradients have been shown to typically have lower variance than REINFORCE gradients or even REINFORCE with control variates. But they do have requirements of having differentiable functions as shown above.